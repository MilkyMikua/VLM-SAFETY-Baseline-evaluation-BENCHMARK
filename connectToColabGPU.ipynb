{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09726d6",
   "metadata": {},
   "source": [
    "# Connection to Colab GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1ca5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f8757",
   "metadata": {},
   "source": [
    "## STEP 2 — Install required VLM packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3b35e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q open_clip_torch transformers sentence-transformers accelerate \\\n",
    "              huggingface_hub pillow matplotlib seaborn pandas safetensors einops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28071a",
   "metadata": {},
   "source": [
    "## STEP 3 — Mount your Google Drive (to load your repo + dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58bbf79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# root = \"/content/drive/MyDrive/VLM_Zheyu/Visionencoder_Rep_Energyfilter\"\n",
    "# os.chdir(root)\n",
    "# print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7891db1",
   "metadata": {},
   "source": [
    "## STEP 4 — Download your manager’s training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1b940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1hw6pERdzH22THudGYoHkJOaZylkh8lu3\n",
      "From (redirected): https://drive.google.com/uc?id=1hw6pERdzH22THudGYoHkJOaZylkh8lu3&confirm=t&uuid=bcfa42b2-9a1d-49b2-a95d-39dba69081ca\n",
      "To: /content/dataset_big\n",
      "100% 2.94G/2.94G [00:41<00:00, 70.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gdown\n",
    "!gdown --id 1hw6pERdzH22THudGYoHkJOaZylkh8lu3 -O /content/dataset_big\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59186ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.8G\n",
      "drwxr-xr-x 3 root root 4.0K Dec 12 06:13 dataset\n",
      "-rw-r--r-- 1 root root 2.8G Nov 22 08:56 dataset_big\n",
      "drwxr-xr-x 4 root root 4.0K Dec 12 06:11 hf_cache\n",
      "-rw-r--r-- 1 root root 175K Dec 12 06:49 hm_pairs_train_small.json\n",
      "-rw-r--r-- 1 root root    0 Dec 12 06:51 leace_results_hm_k5.json\n",
      "drwxr-xr-x 1 root root 4.0K Dec  9 14:42 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9da41",
   "metadata": {},
   "source": [
    "## STEP 5 — Test OpenCLIP on A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa84594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch, os\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38628eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e44b3704f0b47b999ef045210bdfd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/open_clip/factory.py:450: UserWarning: QuickGELU mismatch between final model config (quick_gelu=False) and pretrained tag 'openai' (quick_gelu=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities: [0.13606832921504974, 0.08283153176307678]\n"
     ]
    }
   ],
   "source": [
    "# 2. Simple OpenCLIP test\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    \"ViT-L-14\",\n",
    "    pretrained=\"openai\"\n",
    ")\n",
    "model = model.to(device).eval()\n",
    "\n",
    "tokenizer = open_clip.get_tokenizer(\"ViT-L-14\")\n",
    "\n",
    "# download a test image\n",
    "url = \"https://images.pexels.com/photos/1108099/pexels-photo-1108099.jpeg\"\n",
    "img = Image.open(BytesIO(requests.get(url).content)).convert(\"RGB\")\n",
    "\n",
    "image_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "text_tokens = tokenizer([\"a dog playing in the snow\", \"a car in a city\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_feat = model.encode_image(image_tensor)\n",
    "    txt_feat = model.encode_text(text_tokens)\n",
    "\n",
    "    img_feat = img_feat / img_feat.norm(dim=-1, keepdim=True)\n",
    "    txt_feat = txt_feat / txt_feat.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    sims = (img_feat @ txt_feat.T).squeeze().tolist()\n",
    "\n",
    "print(\"Similarities:\", sims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98636ca0",
   "metadata": {},
   "source": [
    "## Inspect the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a05094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/dataset_big: Zip archive data, at least v2.0 to extract, compression method=store\n"
     ]
    }
   ],
   "source": [
    "!file /content/dataset_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c31cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/dataset:\n",
      "HatefulMemes\n",
      "\n",
      "/content/dataset/HatefulMemes:\n",
      "data\n",
      "\n",
      "/content/dataset/HatefulMemes/data:\n",
      "dev.jsonl\n",
      "img\n",
      "LICENSE.txt\n",
      "README.md\n",
      "test.jsonl\n",
      "train.jsonl\n",
      "\n",
      "/content/dataset/HatefulMemes/data/img:\n",
      "01235.png\n",
      "01236.png\n",
      "01243.png\n",
      "01245.png\n",
      "01247.png\n",
      "01256.png\n",
      "01258.png\n",
      "01264.png\n",
      "01268.png\n",
      "01269.png\n",
      "01274.png\n",
      "01275.png\n",
      "01276.png\n",
      "01284.png\n",
      "01293.png\n",
      "01295.png\n",
      "01324.png\n",
      "01325.png\n",
      "01327.png\n",
      "01329.png\n",
      "01348.png\n",
      "01349.png\n",
      "01359.png\n",
      "01364.png\n",
      "01379.png\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /content/dataset\n",
    "!unzip -q /content/dataset_big -d /content/dataset\n",
    "!ls -R /content/dataset | head -40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e287467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'id': 42953, 'img': 'img/42953.png', 'label': 0, 'text': 'its their character not their color that matters'}\n",
      "1 {'id': 23058, 'img': 'img/23058.png', 'label': 0, 'text': \"don't be afraid to love again everyone is not like your ex\"}\n",
      "2 {'id': 13894, 'img': 'img/13894.png', 'label': 0, 'text': 'putting bows on your pet'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "path = \"/content/dataset/HatefulMemes/data/train.jsonl\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        print(i, json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b42f51",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/VLM_project/train_small_500.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3935223547.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/VLM_project/train_small_500.jsonl'"
     ]
    }
   ],
   "source": [
    "in_path = \"/content/dataset/HatefulMemes/data/train.jsonl\"\n",
    "out_path = \"/content/drive/MyDrive/VLM_project/train_small_500.jsonl\"\n",
    "\n",
    "count = 0\n",
    "with open(in_path, \"r\") as fin, open(out_path, \"w\") as fout:\n",
    "    for line in fin:\n",
    "        fout.write(line)\n",
    "        count += 1\n",
    "        if count >= 500:\n",
    "            break\n",
    "\n",
    "print(\"Wrote\", count, \"examples to\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2242d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/VLM_project')\n",
    "# !pwd\n",
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e0a62c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 500 pairs\n",
      "Saved to /content/hm_pairs_train_500.json\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "in_path = \"/content/dataset/HatefulMemes/data/train_small_500.jsonl\"\n",
    "img_root = \"/content/dataset/HatefulMemes/data\"   # root that contains \"img/\"\n",
    "out_pairs = \"/content/hm_pairs_train_500.json\"\n",
    "\n",
    "pairs = []\n",
    "\n",
    "with open(in_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        ex = json.loads(line)\n",
    "        img_rel = ex[\"img\"]           # e.g. \"img/42953.png\"\n",
    "        caption = ex[\"text\"]\n",
    "        label_id = ex[\"label\"]        # 0 or 1\n",
    "\n",
    "        label = \"safe\" if label_id == 0 else \"unsafe\"\n",
    "        full_img_path = os.path.join(img_root, img_rel)\n",
    "        pairs.append({\n",
    "            \"image\": full_img_path,\n",
    "            \"caption\": caption,\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "print(\"Built\", len(pairs), \"pairs\")\n",
    "with open(out_pairs, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pairs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved to\", out_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa5d70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': '/content/dataset/HatefulMemes/data/img/42953.png',\n",
       "  'caption': 'its their character not their color that matters',\n",
       "  'label': 'safe'},\n",
       " {'image': '/content/dataset/HatefulMemes/data/img/23058.png',\n",
       "  'caption': \"don't be afraid to love again everyone is not like your ex\",\n",
       "  'label': 'safe'},\n",
       " {'image': '/content/dataset/HatefulMemes/data/img/13894.png',\n",
       "  'caption': 'putting bows on your pet',\n",
       "  'label': 'safe'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/content/hm_pairs_train_500.json\", \"r\") as f:\n",
    "    tmp = json.load(f)\n",
    "tmp[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "256869e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for concept-erasure (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/EleutherAI/concept-erasure.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6f41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/content/leace_vlm_eval.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python leace_vlm_eval.py /content/hm_pairs_train_500.json --k 5 --device cuda > /content/leace_results_hm_500_k5.json\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
