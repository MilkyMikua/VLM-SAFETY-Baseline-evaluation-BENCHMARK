{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86861d60",
   "metadata": {},
   "source": [
    "\n",
    "# VLM Safety Evaluation Notebook (Safe-CLIP vs ETA-prefix)\n",
    "\n",
    "This notebook is a **template** to run and compare safety methods on your HatefulMemes-style dataset:\n",
    "\n",
    "- **Baseline**: plain OpenCLIP (inside each eval script)\n",
    "- **Safe-CLIP**\n",
    "- **ETA-prefix** (your retrieval adaptation of ETA, via `eta_eval.py`)\n",
    "\n",
    "It assumes you already have the following scripts in your Google Drive / working directory:\n",
    "\n",
    "- `safe_clip_eval.py` – your working Safe-CLIP evaluation script\n",
    "- `eta_eval.py` – the ETA-prefix evaluation script (the one Trae generated)\n",
    "\n",
    "The notebook will:\n",
    "\n",
    "1. Configure paths and basic settings.\n",
    "2. Run each method on the given split(s) via the Python scripts.\n",
    "3. Load the resulting JSON metric files.\n",
    "4. Aggregate them into a single table.\n",
    "5. Produce simple comparison plots (Recall@K, CLIPScore, semantic shift).\n",
    "\n",
    "> ⚠️ **Note:** This notebook does not re-implement Safe-CLIP or ETA.  \n",
    "> It only orchestrates evaluation using your existing scripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c430d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_DIR: /content/drive/MyDrive/VLM_project/HatefulMemes/data/img\n",
      "SPLITS: {'train': PosixPath('/content/drive/MyDrive/VLM_project/HatefulMemes/data/train_clean.jsonl'), 'dev': PosixPath('/content/drive/MyDrive/VLM_project/HatefulMemes/data/dev_clean.jsonl'), 'test': PosixPath('/content/drive/MyDrive/VLM_project/HatefulMemes/data/test_clean.jsonl')}\n",
      "SAFE_CLIP_EVAL: /content/drive/MyDrive/VLM_project/safe_clip_eval.py\n",
      "ETA_EVAL: /content/drive/MyDrive/VLM_project/eta_eval.py\n",
      "METRICS_DIR: /content/drive/MyDrive/VLM_project/metrics\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- User configuration (edit these) ----------\n",
    "\n",
    "# Base paths (assuming Colab + Google Drive)\n",
    "# Adjust these paths to match your actual layout.\n",
    "DATA_ROOT = Path(\"/content/drive/MyDrive/VLM_project/HatefulMemes/data\")\n",
    "PROJECT_ROOT = Path(\"/content/drive/MyDrive/VLM_project\")\n",
    "\n",
    "# Image directory\n",
    "IMAGE_DIR = DATA_ROOT / \"img\"\n",
    "\n",
    "# JSONL splits (train / dev / test)\n",
    "SPLITS = {\n",
    "    \"train\": DATA_ROOT / \"train_clean.jsonl\",\n",
    "    \"dev\":   DATA_ROOT / \"dev_clean.jsonl\",\n",
    "    \"test\":  DATA_ROOT / \"test_clean.jsonl\",\n",
    "}\n",
    "\n",
    "# Script locations\n",
    "SAFE_CLIP_EVAL = PROJECT_ROOT / \"safe_clip_eval.py\"\n",
    "ETA_EVAL       = PROJECT_ROOT / \"eta_eval.py\"\n",
    "\n",
    "# Where to save metric JSON files\n",
    "METRICS_DIR = PROJECT_ROOT / \"metrics\"\n",
    "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Evaluation parameters\n",
    "K = 5\n",
    "DEVICE = \"cuda\"   # \"cuda\" or \"cpu\"\n",
    "LIMIT = None      # e.g., 500 for a quick debug run; None to use full split\n",
    "\n",
    "# Safety prefix for ETA-prefix variant\n",
    "ETA_SAFETY_PREFIX = (\n",
    "    \"The text must avoid unsafe, porn, violent, politic, physical harmful, \"\n",
    "    \"illegal, privacy and hateful contents.\"\n",
    ")\n",
    "\n",
    "print(\"IMAGE_DIR:\", IMAGE_DIR)\n",
    "print(\"SPLITS:\", SPLITS)\n",
    "print(\"SAFE_CLIP_EVAL:\", SAFE_CLIP_EVAL)\n",
    "print(\"ETA_EVAL:\", ETA_EVAL)\n",
    "print(\"METRICS_DIR:\", METRICS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680d5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "from typing import Optional, Dict\n",
    "\n",
    "def run_python_script(script_path: Path,\n",
    "                      args: Dict[str, Optional[str]],\n",
    "                      dry_run: bool = False):\n",
    "    # Run a Python script with a dict of CLI args.\n",
    "    # Example:\n",
    "    #     run_python_script(\n",
    "    #         SAFE_CLIP_EVAL,\n",
    "    #         {\n",
    "    #             \"--image_dir\": str(IMAGE_DIR),\n",
    "    #             \"--json_path\": str(SPLITS[\"train\"]),\n",
    "    #             \"--output_json\": str(METRICS_DIR / \"safe_clip_train.json\"),\n",
    "    #             \"--k\": str(K),\n",
    "    #             \"--device\": DEVICE,\n",
    "    #         }\n",
    "    #     )\n",
    "    cmd = [\"python\", str(script_path)]\n",
    "    for k, v in args.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        cmd.extend([k, str(v)])\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    if dry_run:\n",
    "        return\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(\"Return code:\", result.returncode)\n",
    "    if result.stdout:\n",
    "        print(\"STDOUT:\\n\", result.stdout[:2000])\n",
    "    if result.stderr:\n",
    "        print(\"STDERR:\\n\", result.stderr[:2000])\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Script failed: {script_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad7174ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Safe-CLIP: train ===\n",
      "Running: python /content/drive/MyDrive/VLM_project/safe_clip_eval.py --image_dir /content/drive/MyDrive/VLM_project/HatefulMemes/data/img --json_path /content/drive/MyDrive/VLM_project/HatefulMemes/data/train_clean.jsonl --output_json /content/drive/MyDrive/VLM_project/metrics/safe_clip_metrics_train.json --k 5 --device cuda\n",
      "Return code: 2\n",
      "STDERR:\n",
      " python3: can't open file '/content/drive/MyDrive/VLM_project/safe_clip_eval.py': [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Script failed: /content/drive/MyDrive/VLM_project/safe_clip_eval.py",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-625834218.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETRICS_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"safe_clip_metrics_{split_name}.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=== Safe-CLIP: {split_name} ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     run_python_script(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mSAFE_CLIP_EVAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         {\n",
      "\u001b[0;32m/tmp/ipython-input-3749679861.py\u001b[0m in \u001b[0;36mrun_python_script\u001b[0;34m(script_path, args, dry_run)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STDERR:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Script failed: {script_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Script failed: /content/drive/MyDrive/VLM_project/safe_clip_eval.py"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Run Safe-CLIP on all splits ===\n",
    "for split_name, json_path in SPLITS.items():\n",
    "    output_json = METRICS_DIR / f\"safe_clip_metrics_{split_name}.json\"\n",
    "    print(f\"\\n=== Safe-CLIP: {split_name} ===\")\n",
    "    run_python_script(\n",
    "        SAFE_CLIP_EVAL,\n",
    "        {\n",
    "            \"--image_dir\": str(IMAGE_DIR),\n",
    "            \"--json_path\": str(json_path),\n",
    "            \"--output_json\": str(output_json),\n",
    "            \"--k\": str(K),\n",
    "            \"--device\": DEVICE,\n",
    "            \"--limit\": str(LIMIT) if LIMIT is not None else None,\n",
    "        },\n",
    "        dry_run=False,  # change to True for debugging commands only\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be9b7ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ETA-prefix: train ===\n",
      "Running: python /content/drive/MyDrive/VLM_project/eta_eval.py --image_dir /content/drive/MyDrive/VLM_project/HatefulMemes/data/img --json_path /content/drive/MyDrive/VLM_project/HatefulMemes/data/train_clean.jsonl --output_json /content/drive/MyDrive/VLM_project/metrics/eta_prefix_metrics_train.json --k 5 --device cuda --safety_prefix The text must avoid unsafe, porn, violent, politic, physical harmful, illegal, privacy and hateful contents.\n",
      "Return code: 2\n",
      "STDERR:\n",
      " python3: can't open file '/content/drive/MyDrive/VLM_project/eta_eval.py': [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Script failed: /content/drive/MyDrive/VLM_project/eta_eval.py",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3452661053.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETRICS_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"eta_prefix_metrics_{split_name}.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=== ETA-prefix: {split_name} ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     run_python_script(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mETA_EVAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         {\n",
      "\u001b[0;32m/tmp/ipython-input-3749679861.py\u001b[0m in \u001b[0;36mrun_python_script\u001b[0;34m(script_path, args, dry_run)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STDERR:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Script failed: {script_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Script failed: /content/drive/MyDrive/VLM_project/eta_eval.py"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Run ETA-prefix (CLIP safety prefix variant) on all splits ===\n",
    "for split_name, json_path in SPLITS.items():\n",
    "    output_json = METRICS_DIR / f\"eta_prefix_metrics_{split_name}.json\"\n",
    "    print(f\"\\n=== ETA-prefix: {split_name} ===\")\n",
    "    run_python_script(\n",
    "        ETA_EVAL,\n",
    "        {\n",
    "            \"--image_dir\": str(IMAGE_DIR),\n",
    "            \"--json_path\": str(json_path),\n",
    "            \"--output_json\": str(output_json),\n",
    "            \"--k\": str(K),\n",
    "            \"--device\": DEVICE,\n",
    "            \"--limit\": str(LIMIT) if LIMIT is not None else None,\n",
    "            \"--safety_prefix\": ETA_SAFETY_PREFIX,\n",
    "        },\n",
    "        dry_run=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d756963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Load metrics for each method & split into a DataFrame ===\n",
    "\n",
    "def load_metrics(method: str, split: str, path: Path) -> pd.Series:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    s = pd.Series(data)\n",
    "    s[\"method\"] = method\n",
    "    s[\"split\"] = split\n",
    "    return s\n",
    "\n",
    "rows = []\n",
    "\n",
    "for split_name in SPLITS.keys():\n",
    "    safe_path = METRICS_DIR / f\"safe_clip_metrics_{split_name}.json\"\n",
    "    if safe_path.exists():\n",
    "        rows.append(load_metrics(\"Safe-CLIP\", split_name, safe_path))\n",
    "\n",
    "    eta_path = METRICS_DIR / f\"eta_prefix_metrics_{split_name}.json\"\n",
    "    if eta_path.exists():\n",
    "        rows.append(load_metrics(\"ETA-prefix\", split_name, eta_path))\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "\n",
    "# Reorder columns a bit\n",
    "cols_order = [\n",
    "    \"method\", \"split\",\n",
    "    \"utility_recall@k_pre_S_V\", \"utility_recall@k_post_S_V\",\n",
    "    \"harmful_recall@k_pre_U_V\", \"harmful_recall@k_post_U_V\",\n",
    "    \"clipscore_safe_pre\", \"clipscore_safe_post\",\n",
    "    \"text_semantic_shift_decline_to_unsafe\",\n",
    "    \"text_semantic_shift_increase_to_neutral\",\n",
    "    \"safety_rates_ASR\", \"safety_rates_USR\",\n",
    "]\n",
    "metrics_df = metrics_df[[c for c in cols_order if c in metrics_df.columns]]\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Plot comparison: Utility & Harmful Recall (pre vs post) ===\n",
    "\n",
    "def plot_bar_for_metric(df: pd.DataFrame, metric_pre: str, metric_post: str, title: str):\n",
    "    # Simple grouped bar chart:\n",
    "    # x-axis: method (per split)\n",
    "    # y-axis: value\n",
    "    # bars: pre vs post\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    groups = df[[\"method\", \"split\"]].drop_duplicates()\n",
    "    x_labels = []\n",
    "    x_positions = []\n",
    "\n",
    "    pre_vals = []\n",
    "    post_vals = []\n",
    "\n",
    "    for _, row in groups.iterrows():\n",
    "        m = row[\"method\"]\n",
    "        s = row[\"split\"]\n",
    "        subset = df[(df[\"method\"] == m) & (df[\"split\"] == s)]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        pre_vals.append(float(subset[metric_pre].iloc[0]))\n",
    "        post_vals.append(float(subset[metric_post].iloc[0]))\n",
    "        x_labels.append(f\"{m}\\n({s})\")\n",
    "        x_positions.append(len(x_positions))\n",
    "\n",
    "    if not x_positions:\n",
    "        print(\"No data to plot for\", title)\n",
    "        return\n",
    "\n",
    "    width = 0.35\n",
    "    x_positions = np.array(x_positions)\n",
    "    ax.bar(x_positions - width/2, pre_vals, width, label=\"pre\")\n",
    "    ax.bar(x_positions + width/2, post_vals, width, label=\"post\")\n",
    "\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(x_labels, rotation=0)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"value\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if not metrics_df.empty:\n",
    "    plot_bar_for_metric(\n",
    "        metrics_df,\n",
    "        \"utility_recall@k_pre_S_V\",\n",
    "        \"utility_recall@k_post_S_V\",\n",
    "        \"Utility Recall@K on Safe Samples\"\n",
    "    )\n",
    "\n",
    "    plot_bar_for_metric(\n",
    "        metrics_df,\n",
    "        \"harmful_recall@k_pre_U_V\",\n",
    "        \"harmful_recall@k_post_U_V\",\n",
    "        \"Harmful Recall@K on Unsafe Samples\"\n",
    "    )\n",
    "\n",
    "    plot_bar_for_metric(\n",
    "        metrics_df,\n",
    "        \"clipscore_safe_pre\",\n",
    "        \"clipscore_safe_post\",\n",
    "        \"CLIPScore on Safe Pairs\"\n",
    "    )\n",
    "else:\n",
    "    print(\"metrics_df is empty – run the evaluation cells first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Plot Semantic Shift metrics ===\n",
    "\n",
    "if not metrics_df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    groups = metrics_df[[\"method\", \"split\"]].drop_duplicates()\n",
    "    x_labels = []\n",
    "    decline_vals = []\n",
    "    increase_vals = []\n",
    "\n",
    "    for _, row in groups.iterrows():\n",
    "        m = row[\"method\"]\n",
    "        s = row[\"split\"]\n",
    "        subset = metrics_df[(metrics_df[\"method\"] == m) & (metrics_df[\"split\"] == s)]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        decline_vals.append(float(subset[\"text_semantic_shift_decline_to_unsafe\"].iloc[0]))\n",
    "        increase_vals.append(float(subset[\"text_semantic_shift_increase_to_neutral\"].iloc[0]))\n",
    "        x_labels.append(f\"{m}\\n({s})\")\n",
    "\n",
    "    if not x_labels:\n",
    "        print(\"No data to plot for semantic shift.\")\n",
    "    else:\n",
    "        x_pos = np.arange(len(x_labels))\n",
    "        width = 0.35\n",
    "        ax.bar(x_pos - width/2, decline_vals, width, label=\"decline_to_unsafe\")\n",
    "        ax.bar(x_pos + width/2, increase_vals, width, label=\"increase_to_neutral\")\n",
    "\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(x_labels)\n",
    "        ax.set_title(\"Semantic Shift Metrics\")\n",
    "        ax.set_ylabel(\"cosine similarity change\")\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"metrics_df is empty – run the evaluation cells first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a0817",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps / Interpretation Tips\n",
    "\n",
    "Once you have the metrics:\n",
    "\n",
    "- **Utility vs Safety Trade-off**\n",
    "  - Compare `utility_recall@k_*` (safe) vs `harmful_recall@k_*` (unsafe).\n",
    "  - A good safety method should **reduce harmful recall** while ideally keeping **utility recall** high.\n",
    "\n",
    "- **CLIPScore**\n",
    "  - Large drops in `clipscore_safe_post` often mean the method is suppressing *all* signal,\n",
    "    not just unsafe associations.\n",
    "\n",
    "- **Semantic Shift**\n",
    "  - `text_semantic_shift_decline_to_unsafe` > 0 means embeddings move **away from unsafe centroid**.\n",
    "  - `text_semantic_shift_increase_to_neutral` > 0 means embeddings move **toward neutral centroid**.\n",
    "  - A strong safety method ideally has both positive (or at least non-negative) values.\n",
    "\n",
    "You can also add more cells to:\n",
    "- Load LOSF results once you implement it.\n",
    "- Add more advanced plots or per-class breakdowns.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
